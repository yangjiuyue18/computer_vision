Вопросы к экзамену по дисциплине «Компьютерное зрение»
1. Задачи компьютерного зрения.
2. Постановка задачи обнаружения границ объектов на изображении. Детекторы границ.
3. Детектор границ Кэнни.
4. Преобразование Хафа. Алгоритм обнаружения линий. Алгоритм обнаружения окружностей.
5. Обнаружение особых точек на изображении. Детектор Моравеца.
6. Обнаружение особых точек на изображении. Детектор Харриса. Детектор Shi-Tomasi.
7. Масштабно-инвариантная трансформация признаков (SIFT).
8. Постановка задачи классификации изображений. Линейный классификатор. SVM. Мешок
визуальных слов.
9. Архитектура нейронной сети для классификации изображений.
10. Постановка задачи локализации объекта на изображении. Метрики.
11. Архитектура нейронной сети для локализации объекта на изображении.
12. Постановка задачи обнаружения объектов на изображении. R-CNN.
13. Обнаружения объектов на изображении. Fast R-CNN и Faster R-CNN.
14. Обнаружения объектов на изображении. Single Short Detector.
15. Постановка задачи сегментации изображений. FCN.
16. Архитектура U-Net.
17. Архитектура Mask R-CNN.
18. Метод оценки оптического потока Лукаса-Канаде.
19. Метод оценки оптического потока Horn-Schunck.
20. Нейронные сети для задачи вычисления оптического потока.
21. Задача отслеживания объектов на изображении (Object Tracking).
22. Задача распознавания лиц. Каскады Хаара.
23. Задача распознавания лиц. FaceNet.
24. Постановка задачи поиска изображений. Подходы к её решению.
25. Задача распознавания текста. Подходы к её решению.

## 1. 计算机视觉的任务  Задачи компьютерного зрения

计算机视觉是一门研究如何让计算机通过图像或视频来感知、理解和分析周围环境的学科，其主要任务包括以下几个方面：
1. **图像分类 / классификация изображений / image classification**
   给定一张图片，将其归类为某一类别。例如，识别图片中的内容是猫、狗还是汽车。
2. **目标检测 / обнаружение цели / target detection**  
   在图像中找到特定的目标，并标注其所在的位置（通常用边界框表示）。
3. **图像分割 / сегментация изображения / image segmentation**  
   将图像划分为不同的区域，使每个像素都被分类为特定的类别。分为语义分割（按类别标注像素）和实例分割（分离不同个体）。
4. **目标跟踪 / Целевое отслеживание / object tracking**
   在视频中跟踪一个或多个目标的移动轨迹。
5. **光流估计 / Оценка оптического потока / Optical Flow Estimation**  
   分析图像序列中像素的运动，用于运动分析和视频稳定等任务。
6. **人脸识别 / Распознавание лиц / face recognition**  
   识别图像或视频中的人脸，广泛用于身份验证和监控。
7. **图像生成与增强 / image generation and enhancement**  
   生成新图像或增强现有图像，例如超分辨率、风格迁移和去噪处理。
8. **三维重建 / 3D реконструкция / 3D reconstruction**  
   从二维图像或视频中恢复物体的三维结构。
9. **文本识别（OCR） / text recognition (OCR)**  
   从图像中提取文字信息，用于文档数字化和车牌识别等。
10. **场景理解 / scene understanding**  
    综合分析图像中的多个元素，理解整个场景的语义内容。

计算机视觉的核心在于模仿人类视觉系统，通过算法、模型和工具使机器能够“看懂”图像，并作出相应的反应或决策。这些任务广泛应用于自动驾驶、医疗影像分析、安防监控、虚拟现实等领域。

## 2. 在图像上检测对象边界的问题定义。边缘检测器 Постановка задачи обнаружения границ объектов на изображении. Детекторы границ

边缘检测是计算机视觉中的一项基本任务，旨在从图像中提取出对象的轮廓或边界。边缘通常对应于图像中亮度变化剧烈的区域，是图像中最重要的结构之一。边缘检测的目的是在图像中找到这些突变点，即**图像像素灰度值（Image Pixel Intensity || Интенсивность пикселя изображения）** 急剧变化的地方，以便将对象从背景中分离出来。
### 边缘检测的问题定义
边缘检测的目标是通过分析图像中的灰度变化，识别出图像中具有明显变化的部分，通常这些变化代表着物体的边缘。具体任务可以定义为：  
- 对输入图像进行处理，识别出明显的边缘区域。  
- 输出一个二值化图像，其中边缘区域被标识为白色，其余部分为黑色。
### 边缘检测器 Детекторы границ || Edge Detector
边缘检测器是一种用于执行边缘检测任务的算法或滤波器。常见的边缘检测器包括：
1. **Sobel算子 / Sobel Operator**  
   Sobel算子是一种简单的边缘检测方法，它通过计算图像灰度值的梯度来确定边缘的位置。Sobel算子有两个方向的滤波器，一个用于检测水平边缘，另一个用于检测垂直边缘。通过计算水平和垂直梯度的组合，可以得到边缘强度。
2. **Prewitt算子 / Prewitt Operator**  
   Prewitt算子与Sobel算子相似，也是通过计算图像的梯度来进行边缘检测。其主要区别在于使用的卷积核略有不同，Prewitt算子通常被认为在某些情况下更适合检测较大尺度的边缘。
3. **Canny边缘检测器 / Canny Edge Detector**  
   Canny边缘检测器是最常用的边缘检测方法之一，它包含多个步骤：  
   - **高斯滤波 / Gaussian blur**：用于平滑图像，减少噪声的影响。  
   - **梯度计算 / Gradient Computation**：计算每个像素的梯度方向和幅值。  
   - **非极大值抑制 / Non-Maximum Suppression**：通过抑制非边缘像素来细化边缘。  
   - **双阈值 / Double Threshold**：使用高低两个阈值来确定强边缘、弱边缘和非边缘区域。  
   - **边缘连接 / Edge Linking**：通过连接弱边缘与强边缘来完成最终的边缘检测。
4. **Laplace算子 / Laplace Operator**  
   Laplace算子是一种基于二阶导数的边缘检测方法，它可以检测到图像中的急剧灰度变化。常见的应用包括图像的轮廓提取。
5. **Roberts算子 / Roberts Operator**  
   Roberts算子是一种基于邻域差异的边缘检测方法，它通过计算像素之间的梯度差异来确定边缘的位置，通常用于检测细小的边缘。
6. **Kirsch算子 /  Kirsch Operator**  
   Kirsch算子是一种方向性边缘检测方法，它通过在多个方向上计算图像的梯度值来检测边缘。这种方法通常用于检测具有特定方向的边缘。
### 边缘检测的应用
- **物体识别 / Object Recognition**：通过检测图像中的边缘，可以帮助系统识别出物体的轮廓并进行进一步分析。
- **图像分割 / Image Segmentation**：边缘检测是图像分割的一个重要步骤，可以将图像中的不同区域进行分离。
- **特征提取 / Feature Extraction**：边缘通常包含图像中的重要信息，边缘检测可以帮助提取这些信息，用于后续的图像分析任务。
- **图像增强 / Image Enhancement**：通过边缘检测可以对图像进行增强，突出显示图像中的重要结构。

通过边缘检测，计算机能够从图像中提取出更为清晰、精确的信息，进而完成如目标检测、图像分割等更复杂的任务。

## 3. Canny边缘检测器 Детектор границ Кэнни

Canny边缘检测器Canny Edge Detector是一种多步骤的边缘检测算法，其目标是检测图像中的边缘，同时减少噪声和伪边缘的影响。Canny算法具有以下步骤：  
1. **高斯滤波 / Gaussian Filter**：平滑图像以降低噪声。  
2. **梯度计算 / Gradient Calculation**：计算图像中每个像素点的梯度幅值和方向。  
3. **非极大值抑制 / Non-maximum Suppression**：通过抑制梯度方向上的非最大值像素，精确定位边缘。  
4. **双阈值处理 / Double Thresholding**：使用高低阈值筛选出强边缘和弱边缘。  
5. **边缘连接 / Edge Connection**：通过弱边缘连接强边缘形成最终结果。

### OpenCV伪代码函数  
```python
def canny_edge_detection(image, low_threshold, high_threshold, kernel_size):
    """
    Canny边缘检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param low_threshold: 低阈值，用于筛选弱边缘。
    :param high_threshold: 高阈值，用于筛选强边缘。
    :param kernel_size: 高斯滤波器的核大小，用于平滑图像。
    :return: 检测到边缘的二值图像。
    """
    # Step 1: 高斯滤波去噪
    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    # Step 2: Canny边缘检测
    edges = cv2.Canny(blurred_image, low_threshold, high_threshold)
    return edges
```
### 参数解释  
1. **`image`**  
   - 输入图像，通常为灰度图像。  
   - 类型：二维数组。  
2. **`low_threshold`**  
   - 较低的阈值，用于识别弱边缘。如果某个像素的梯度值小于此阈值，将被视为非边缘。  
   - 类型：整数。  
3. **`high_threshold`**  
   - 较高的阈值，用于识别强边缘。如果某个像素的梯度值大于此阈值，将直接视为边缘。  
   - 类型：整数。  
4. **`kernel_size`**  
   - 高斯滤波器的核大小，通常为奇数（如3、5、7）。核越大，图像平滑程度越高，但可能导致细节损失。  
   - 类型：整数。  
5. **返回值**  
   - 一个二值图像，其中白色像素表示边缘，黑色像素表示非边缘。  
   - 类型：二维数组。  

假设我们有一幅灰度图像 `img`：  
```python
edges = canny_edge_detection(img, low_threshold=50, high_threshold=150, kernel_size=3)
cv2.imshow('Canny Edges', edges)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
这样，就可以根据阈值调节边缘检测的灵敏度，最终得到检测到的边缘。

## 4. 霍夫变换。直线检测算法。圆形检测算法 Преобразование Хафа. Алгоритм обнаружения линий. Алгоритм обнаружения окружностей

霍夫变换是一种用来从图像中检测几何形状（如直线、圆形等）的方法。其核心思想是将几何形状的检测问题转化为参数空间的搜索问题。

1. **直线检测 / Line Detection**  
   通过将图像中的点转换到参数空间，寻找所有共线点的参数组合，最终找到直线。  
   参数方程：  
   \[
   \rho = x \cdot \cos\theta + y \cdot \sin\theta
   \]  
   其中：  
   - \(\rho\)：点到原点的距离。  
   - \(\theta\)：点到原点的垂线与x轴的夹角。  

2. **圆形检测 / Circle Detection**  
   圆的参数方程为：  
   \[
   (x - a)^2 + (y - b)^2 = r^2
   \]  
   在霍夫空间中搜索符合圆形方程的点。

### 直线检测 / Line Detection
```python
def hough_line_detection(image, rho, theta, threshold):
    """
    霍夫直线检测伪代码函数

    :param image: 输入图像，通常为边缘检测后的二值图像。
    :param rho: 累积器中距离分辨率，单位为像素。
    :param theta: 累积器中角度分辨率，单位为弧度。
    :param threshold: 最小投票数，表示检测到直线所需的支持点数。
    :return: 检测到的直线的参数 (rho, theta)。
    """
    lines = cv2.HoughLines(image, rho, theta, threshold)
    return lines
```

### 圆形检测 / Circle Detection
```python
def hough_circle_detection(image, dp, min_dist, param1, param2, min_radius, max_radius):
    """
    霍夫圆形检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param dp: 累积器分辨率与输入图像分辨率的反比关系。
    :param min_dist: 检测到的圆之间的最小距离，避免多个重叠圆。
    :param param1: Canny边缘检测的高阈值。
    :param param2: 用于圆心检测的累积器阈值。
    :param min_radius: 检测圆的最小半径。
    :param max_radius: 检测圆的最大半径。
    :return: 检测到的圆的参数 (x, y, r)。
    """
    circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT, dp, min_dist, param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
    return circles
```
## 参数解释  

### 直线检测  
1. **`image`**  
   - 输入二值图像，通常通过边缘检测器（如Canny）预处理。  

2. **`rho`**  
   - 距离分辨率（像素单位），决定霍夫空间的累积精度。  

3. **`theta`**  
   - 角度分辨率（弧度单位），通常为 \(\pi/180\) 或更小。  

4. **`threshold`**  
   - 检测到直线所需的最小累积票数。  

### 圆形检测  
1. **`dp`**  
   - 累积器分辨率与输入图像分辨率的比值，值越大，计算越快，但可能遗漏细节。  

2. **`min_dist`**  
   - 检测到的圆之间的最小距离，避免检测到重叠的圆。  

3. **`param1`**  
   - Canny边缘检测器的高阈值，影响边缘检测结果。  

4. **`param2`**  
   - 用于圆心检测的累积器阈值，值越大，检测的圆越严格。  

5. **`min_radius` 和 `max_radius`**  
   - 圆的最小和最大半径，用于限制检测范围。  

### 直线检测
```python
edges = cv2.Canny(img, 50, 150)
lines = hough_line_detection(edges, rho=1, theta=np.pi/180, threshold=100)
for line in lines:
    rho, theta = line[0]
    a, b = np.cos(theta), np.sin(theta)
    x0, y0 = a * rho, b * rho
    x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * a)
    x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * a)
    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
```

### 圆形检测
```python
circles = hough_circle_detection(gray_img, dp=1, min_dist=20, param1=50, param2=30, min_radius=10, max_radius=50)
for circle in circles[0, :]:
    x, y, r = circle
    cv2.circle(img, (x, y), r, (0, 255, 0), 2)
    cv2.circle(img, (x, y), 2, (255, 0, 0), 3)
```

## 5. 图像上的特征点检测。Moravec检测器 Обнаружение особых точек на изображении. Детектор Моравеца

**Moravec检测器**是最早的**角点(Угол | Corner)** 检测算法之一，用于在图像中识别具有显著特征的点（如角点）。其基本思想是：一个点在多个方向上的灰度变化显著时，可被认为是一个特征点。

Moravec检测器通过计算像素邻域在各个方向上的强度变化，判断某个像素点是否是角点。如果变化超过一定的阈值，则该点被标记为角点。

```python
def moravec_detector(image, window_size, threshold):
    """
    Moravec特征点检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param window_size: 窗口大小，用于计算像素邻域的强度变化。
    :param threshold: 角点强度的最小值，超过此值的点被认为是角点。
    :return: 标记了角点的二值图像。
    """
    # 获取图像尺寸
    rows, cols = image.shape
    # 初始化角点响应矩阵
    response = np.zeros_like(image, dtype=np.float32)

    offset = window_size // 2

    # 遍历图像每个像素
    for y in range(offset, rows - offset):
        for x in range(offset, cols - offset):
            # 初始化最小变化值
            min_variance = float('inf')

            # 遍历四个方向（水平、垂直、两个对角线）
            for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                # 计算窗口内的强度差平方和
                variance = 0
                for i in range(-offset, offset + 1):
                    for j in range(-offset, offset + 1):
                        try:
                            diff = image[y + j, x + i] - image[y + j + dy, x + i + dx]
                            variance += diff ** 2
                        except IndexError:
                            pass

                # 更新最小变化值
                min_variance = min(min_variance, variance)

            # 将最小变化值存入响应矩阵
            response[y, x] = min_variance

    # 应用阈值以识别角点
    corners = np.zeros_like(image, dtype=np.uint8)
    corners[response > threshold] = 255

    return corners
```
1. **`image`**  
   - 输入图像，通常为灰度图像。  
   - 类型：二维数组。  
2. **`window_size`**  
   - 用于计算局部变化的窗口大小，通常为奇数（如3、5）。较大的窗口适合检测大尺度特征点。  
   - 类型：整数。  
3. **`threshold`**  
   - 用于判断角点强度的阈值，越大表示更严格的角点选择。  
   - 类型：浮点数或整数。  
4. **返回值**  
   - 一个二值图像，其中白色像素表示检测到的角点，黑色像素表示非角点。  

```python
# 读取灰度图像
gray_img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)
# 使用Moravec检测器
corners = moravec_detector(gray_img, window_size=3, threshold=100)
# 可视化结果
cv2.imshow('Moravec Corners', corners)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
## 应用场景  
- **特征匹配**：用于图像拼接、图像对齐。  
- **目标跟踪**：识别图像中稳定的特征点，用于目标的运动分析。  
- **图像分割**：在分割时增强区域边界信息。

## 6. 图像上的特征点检测。Harris检测器。Shi-Tomasi检测器 Обнаружение особых точек на изображении. Детектор Харриса. Детектор Shi-Tomasi

**Harris检测器**是基于图像灰度变化的角点检测算法，其利用二阶导数和矩阵特征值来评估一个点是否是角点。它的特点是能够检测到稳定、显著的角点，且对噪声较为鲁棒。  
**Shi-Tomasi检测器**是对Harris检测器的改进版本，它通过直接比较矩阵的最小特征值来判断角点的显著性，而非通过组合特征值的响应函数，从而提高了检测精度。

### Harris检测器
```python
def harris_detector(image, block_size, ksize, k, threshold):
    """
    Harris角点检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param block_size: 邻域窗口大小，用于计算角点检测的结构张量矩阵。
    :param ksize: Sobel算子的核大小，用于计算图像梯度。
    :param k: Harris响应公式中的敏感系数，通常在 [0.04, 0.06] 之间。
    :param threshold: 用于角点筛选的响应阈值。
    :return: 标记了角点的二值图像。
    """
    # 计算Harris角点响应
    harris_response = cv2.cornerHarris(image, block_size, ksize, k)
    # 标记角点
    corners = np.zeros_like(image, dtype=np.uint8)
    corners[harris_response > threshold * harris_response.max()] = 255
    return corners
```
### Shi-Tomasi检测器
```python
def shi_tomasi_detector(image, max_corners, quality_level, min_distance):
    """
    Shi-Tomasi角点检测伪代码函数
    :param image: 输入图像，通常为灰度图像。
    :param max_corners: 最大角点数，检测到的角点不会超过此值。
    :param quality_level: 角点质量的最低值，取值范围为 [0, 1]。
    :param min_distance: 角点之间的最小欧几里得距离。
    :return: 角点的坐标列表。
    """
    # 使用Shi-Tomasi检测器
    corners = cv2.goodFeaturesToTrack(image, max_corners, quality_level, min_distance)
    return corners
```
### Harris检测器
1. **`image`**  
   - 输入灰度图像。  
2. **`block_size`**  
   - 计算结构张量矩阵的邻域窗口大小。  
3. **`ksize`**  
   - Sobel算子的核大小，通常为3或5。  
4. **`k`**  
   - Harris响应函数的敏感系数，较小的值更敏感，但可能增加噪声。  
5. **`threshold`**  
   - 用于筛选角点的响应阈值，超过此值的点被认为是角点。  
### Shi-Tomasi检测器
1. **`max_corners`**  
   - 最大角点数，用于限制检测的角点数量。  
2. **`quality_level`**  
   - 角点响应的最低质量因子，较高值会过滤掉弱角点。  
3. **`min_distance`**  
   - 角点之间的最小距离，用于避免角点过于密集。  

### Harris检测器
```python
gray_img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)
# Harris角点检测
harris_corners = harris_detector(gray_img, block_size=2, ksize=3, k=0.04, threshold=0.01)
# 可视化结果
cv2.imshow('Harris Corners', harris_corners)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
### Shi-Tomasi检测器
```python
gray_img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)
# Shi-Tomasi角点检测
shi_tomasi_corners = shi_tomasi_detector(gray_img, max_corners=100, quality_level=0.01, min_distance=10)
# 可视化角点
for corner in shi_tomasi_corners:
    x, y = corner.ravel()
    cv2.circle(gray_img, (int(x), int(y)), 3, (255, 0, 0), -1)
cv2.imshow('Shi-Tomasi Corners', gray_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
### 应用场景  
1. **目标跟踪**：检测关键点以实现跟踪。  
2. **图像拼接**：通过角点匹配对齐图像。  
3. **三维重建**：角点是立体匹配的关键特征。  

## 7. 尺度不变特征变换（SIFT）Scale-Invariant Feature Transform (SIFT) | Масштабно-инвариантное преобразование признаков (SIFT)

**SIFT**（Scale-Invariant Feature Transform）是一种用于检测和描述图像局部特征点的算法，具有尺度不变性、旋转不变性以及部分仿射变换不变性。SIFT通过检测图像中的稳定特征点并为其计算描述符，广泛用于图像匹配、拼接、三维重建、物体识别等计算机视觉任务。
SIFT的核心思想是，在不同的尺度下检测图像的关键点，通过对每个关键点周围的局部区域进行描述，使得即使图像旋转、缩放或改变亮度，仍然能够找到相似的特征点。

```python
def sift_detector(image, nfeatures=0, contrast_threshold=0.04, edge_threshold=10, sigma=1.6):
    """
    SIFT特征点检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param nfeatures: 返回的最大特征点数（默认0表示不限制）。
    :param contrast_threshold: 用于抑制低对比度的特征点的阈值。
    :param edge_threshold: 用于过滤不稳定特征点的阈值。
    :param sigma: 高斯模糊的标准差，用于构建尺度空间。
    :return: 特征点和描述符。
    """
    # 创建SIFT对象
    sift = cv2.SIFT_create(nfeatures, contrastThreshold=contrast_threshold, edgeThreshold=edge_threshold, sigma=sigma)

    # 检测特征点并计算描述符
    keypoints, descriptors = sift.detectAndCompute(image, None)

    return keypoints, descriptors
```
1. **`image`**  
   - 输入灰度图像。  
2. **`nfeatures`**  
   - 需要返回的最大特征点数量。值为0时表示没有上限。  
3. **`contrast_threshold`**  
   - 用于抑制对比度较低的特征点的阈值，较大的值可以去除噪声和不显著的点。  
4. **`edge_threshold`**  
   - 用于剔除边缘响应较弱的特征点的阈值，防止检测到不稳定的点。  
5. **`sigma`**  
   - 用于构建尺度空间的高斯模糊的标准差。  
6. **返回值**  
   - **`keypoints`**：图像中的特征点列表，每个特征点包含其位置、尺度、方向等信息。  
   - **`descriptors`**：每个特征点的描述符，通常是一个向量，用于表示该点的局部特征。

```python
# 读取灰度图像
gray_img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)
# 使用SIFT检测特征点和描述符
keypoints, descriptors = sift_detector(gray_img)
# 在图像中绘制特征点
img_with_keypoints = cv2.drawKeypoints(gray_img, keypoints, None)
# 可视化结果
cv2.imshow('SIFT Keypoints', img_with_keypoints)
cv2.waitKey(0)
cv2.destroyAllWindows()
```
1. **图像匹配**：通过特征点及其描述符匹配不同图像中的相同物体或场景。  
2. **三维重建**：通过匹配不同视角下的特征点来重建三维场景。  
3. **物体识别**：在变化的环境下，基于特征点识别物体。  
4. **图像拼接**：通过特征点匹配来对齐图像，创建全景图像。
SIFT是一个非常强大的特征点检测方法，能处理大量的变化（如缩放、旋转、光照变化等）
## 8. 图像分类任务的定义。线性分类器、支持向量机（SVM）、视觉词袋模型 Постановка задачи классификации изображений. Линейный классификатор. SVM. Мешок визуальных слов  
**图像分类**是计算机视觉中的基础任务之一，其目标是将图像划分到一个或多个预定类别中。为了实现这一目标，通常会通过特征提取方法将图像转化为数值向量，再通过机器学习模型进行分类。常见的图像分类方法包括**支持向量机**（SVM）和**视觉词袋模型**（Bag of Visual Words, BoVW）。
### SVM（支持向量机）
SVM是一种经典的监督学习方法，主要用于二分类和多分类问题。SVM通过寻找一个“最佳超平面”将不同类别的样本进行分离，它具有较强的泛化能力，能够在高维空间中处理复杂的分类任务。对于图像分类，SVM通常结合图像的局部特征（如SIFT、HOG等）来进行分类。
### 视觉词袋模型（BoVW）
视觉词袋模型借鉴了自然语言处理中的词袋模型。它将图像中的特征描述符（如SIFT）进行量化，生成一个固定大小的“视觉词汇”，然后通过这些视觉词汇来表示图像。每个图像被看作是一个“词袋”，而分类则通过这些“视觉单词”的频率分布进行。
### 应用场景
1. **图像分类**  
   图像分类是SVM和视觉词袋模型的经典应用，可以用于将图像分类为不同的类别（如“狗”与“猫”）。
2. **物体识别**  
   使用图像的局部特征进行物体检测和识别，例如在一个场景中识别出“汽车”或“建筑物”。
3. **内容检索**  
   基于图像特征的相似性进行图像检索，即根据用户提供的图像查询数据库中的相似图像。

## 9. 图像分类神经网络的架构 Архитектура нейронной сети для классификации изображений

神经网络架构通常包含多个层次，具体包括：
- **输入层**：接收输入数据，如图像的像素值。
- **隐藏层**：通过神经元和激活函数进行非线性变换。
- **输出层**：输出分类结果，通常使用Softmax激活函数来计算类别的概率分布。
### 卷积神经网络（CNN）
卷积神经网络（CNN）是一类特别适用于图像数据的神经网络，它通过卷积层、池化层和全连接层等构建图像的特征表示。
1. **卷积层**  
   卷积层通过卷积运算提取图像的局部特征（如边缘、角点、纹理等）。卷积操作是局部感知的，这意味着每个卷积核只与图像的一部分区域进行运算。
2. **池化层**  
   池化层用于减少卷积层输出的空间维度，降低计算复杂度。常见的池化操作有最大池化（Max Pooling）和平均池化（Average Pooling）。
3. **全连接层**  
   全连接层连接所有的神经元，通常位于网络的最后阶段，用于对特征进行分类。
4. **激活函数**  
   激活函数（如ReLU、Sigmoid、Softmax等）用于引入非线性因素，使得网络可以学习复杂的模式。
### 网络训练与优化
神经网络的训练过程主要通过反向传播算法（Backpropagation）和梯度下降法（Gradient Descent）来完成。
1. **损失函数**  
   损失函数用于衡量网络的预测结果与真实标签之间的差距，常用的损失函数有交叉熵损失（Cross-Entropy Loss）等。
2. **反向传播**  
   反向传播算法用于计算损失函数关于网络参数的梯度，并通过梯度下降法调整网络权重。
3. **优化器**  
   优化器（如Adam、SGD等）通过不断调整网络的权重，减少损失函数的值，达到最优分类效果。
### 应用
神经网络，特别是CNN，在以下领域得到了广泛应用：
1. **图像分类**  
   通过神经网络将图像分类到不同类别，例如物体识别、人脸识别等。
2. **目标检测**  
   在图像中找到特定目标并进行定位，应用于自动驾驶、视频监控等领域。
3. **图像分割**  
   将图像划分为多个语义区域，用于医学影像分析、遥感图像处理等。
4. **图像生成**  
   使用生成对抗网络（GAN）等生成模型从噪声中生成逼真的图像。

## 10. 图像上目标定位问题的定义。评价指标 Постановка задачи локализации объекта на изображении. Метрики.

**物体定位**（Object Localization）是计算机视觉中的一个任务，它的目标是在图像中精确地确定一个或多个物体的位置。通常，定位任务不仅需要识别物体的类别，还要标注其在图像中的位置，通常是通过边界框（bounding box）来表示。
在物体检测任务中，物体定位的精度评估是非常重要的，它直接影响到检测算法的效果。定位精度通常通过不同的**度量标准**来衡量。
### 评估标准
1. **交并比（IoU, Intersection over Union）**  
   **交并比**是用于评估预测边界框与真实边界框重叠度的一个指标。IoU 是通过计算预测框与真实框的交集面积与它们的并集面积之比来得到的。其公式为：
   \[
   IoU = \frac{Area\ of\ Intersection}{Area\ of\ Union}
   \]
   - **值范围**：0 到 1，值越大表示预测框与真实框的重叠程度越高，检测精度越高。
   - **应用**：IoU 用于决定检测结果是否是一个有效的检测，通常会设置一个阈值（如 0.5），如果 IoU 大于该阈值，则认为检测是有效的。
2. **定位精度**  
   定位精度是指预测的边界框与真实边界框之间的位置误差。常见的度量方式有：
   - **中心点误差**：计算预测边界框的中心点与真实边界框中心点之间的距离。
   - **边界框尺寸误差**：比较预测框与真实框的宽度和高度之间的差异。
3. **平均精度（mAP, mean Average Precision）**  
   平均精度是物体检测中常用的评价指标，通常用来评估多个物体类别下的检测性能。mAP 是通过计算每个类别的平均精度（AP），然后对所有类别的 AP 进行平均得到的。AP 的计算方法一般是通过绘制精度-召回曲线并计算其下面积。
   - **公式**：mAP = \(\frac{1}{n} \sum_{i=1}^{n} AP_i\)
     - \(n\)：类别的总数
     - \(AP_i\)：类别 i 的平均精度。
   mAP 越高，说明检测模型在各个类别上的检测效果越好。
4. **召回率与精确率（Recall & Precision）**
   - **精确率（Precision）**：预测为正样本的边界框中，真正为正样本的比例。
     \[
     Precision = \frac{TP}{TP + FP}
     \]
     其中 TP 是真正例，FP 是假正例。
   - **召回率（Recall）**：所有真实正样本中，被正确预测的比例。
     \[
     Recall = \frac{TP}{TP + FN}
     \]
     其中 TP 是真正例，FN 是假负例。
   在定位任务中，精确率和召回率通常是相互制约的，因此需要平衡这两者。

1. **自动驾驶**  
   在自动驾驶系统中，物体定位评估非常关键，车辆需要精确定位道路上的行人、车辆、交通标志等物体。高精度的物体定位能帮助自动驾驶系统做出更安全的决策。
2. **视频监控**  
   视频监控系统需要识别并定位场景中的异常物体或行为。定位精度评估可以帮助提升监控系统的有效性和响应速度。
3. **医疗影像**  
   在医学影像分析中，定位精度尤为重要。例如，肿瘤检测需要精确地定位肿瘤在图像中的位置，从而为医生提供准确的诊断信息。
### 总结
物体定位的精度评估是物体检测任务中不可忽视的环节，交并比（IoU）是最常用的定位评估指标。定位精度、mAP、精确率与召回率也是衡量检测精度的重要标准。根据具体应用场景，优化定位精度的评估指标可以大大提升物体检测算法的实际效果和应用价值。 
## 11. 用于目标定位的神经网络架构。  
## 12. 图像目标检测问题的定义。R-CNN。  
13. 图像目标检测方法：Fast R-CNN和Faster R-CNN。  
14. 图像目标检测方法：单发检测器（Single Shot Detector, SSD）。  
15. 图像分割问题的定义。全卷积网络（FCN）。  
16. U-Net架构。  
17. Mask R-CNN架构。  
18. Lucas-Kanade光流估计方法。  
19. Horn-Schunck光流估计方法。  
20. 计算光流任务的神经网络。  
21. 图像中的目标跟踪任务（Object Tracking）。  
22. 人脸识别任务。Haar级联分类器。  
23. 人脸识别任务。FaceNet方法。  
24. 图像检索任务的定义及其解决方法。  
25. 文本识别任务及其解决方法。  