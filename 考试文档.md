Вопросы к экзамену по дисциплине «Компьютерное зрение»
1. Задачи компьютерного зрения.
2. Постановка задачи обнаружения границ объектов на изображении. Детекторы границ.
3. Детектор границ Кэнни.
4. Преобразование Хафа. Алгоритм обнаружения линий. Алгоритм обнаружения окружностей.
5. Обнаружение особых точек на изображении. Детектор Моравеца.
6. Обнаружение особых точек на изображении. Детектор Харриса. Детектор Shi-Tomasi.
7. Масштабно-инвариантная трансформация признаков (SIFT).
8. Постановка задачи классификации изображений. Линейный классификатор. SVM. Мешок
визуальных слов.
9. Архитектура нейронной сети для классификации изображений.
10. Постановка задачи локализации объекта на изображении. Метрики.
11. Архитектура нейронной сети для локализации объекта на изображении.
12. Постановка задачи обнаружения объектов на изображении. R-CNN.
13. Обнаружения объектов на изображении. Fast R-CNN и Faster R-CNN.
14. Обнаружения объектов на изображении. Single Short Detector.
15. Постановка задачи сегментации изображений. FCN.
16. Архитектура U-Net.
17. Архитектура Mask R-CNN.
18. Метод оценки оптического потока Лукаса-Канаде.
19. Метод оценки оптического потока Horn-Schunck.
20. Нейронные сети для задачи вычисления оптического потока.
21. Задача отслеживания объектов на изображении (Object Tracking).
22. Задача распознавания лиц. Каскады Хаара.
23. Задача распознавания лиц. FaceNet.
24. Постановка задачи поиска изображений. Подходы к её решению.
25. Задача распознавания текста. Подходы к её решению.

## 1. 计算机视觉的任务  Задачи компьютерного зрения

1. **图像分类 / классификация изображений / image classification**
2. **目标检测 / обнаружение цели / target detection**  
3. **图像分割 / сегментация изображения / image segmentation**  
4. **目标跟踪 / Целевое отслеживание / object tracking**
5. **光流估计 / Оценка оптического потока / Optical Flow Estimation**  
6. **人脸识别 / Распознавание лиц / face recognition**
7. **文本识别（OCR） / text recognition (OCR)**  

## 2. 在图像上检测对象边界的问题定义。边缘检测器 Постановка задачи обнаружения границ объектов на изображении. Детекторы границ

边缘检测是计算机视觉中的一项基本任务，旨在从图像中提取出对象的轮廓或边界。边缘通常对应于图像中亮度变化剧烈的区域，是图像中最重要的结构之一。边缘检测的目的是在图像中找到这些突变点，即图像像素(Pixel)**灰度值（Grayscale Value || Значение градации серого）** 急剧变化的地方，以便将对象从背景中分离出来。
### 边缘检测的问题定义
边缘检测的目标是通过分析图像中的灰度变化，识别出图像中具有明显变化的部分，通常这些变化代表着物体的边缘。具体任务可以定义为：  
- 对输入图像进行处理，识别出明显的边缘区域。  
- 输出一个二值化图像，其中边缘区域被标识为白色，其余部分为黑色。
### 边缘检测器 Детекторы границ || Edge Detector
边缘检测器是一种用于执行边缘检测任务的算法或滤波器。常见的边缘检测器包括：
1. **Sobel算子 / Sobel Operator**  
   Sobel算子是一种简单的边缘检测方法，它通过计算图像灰度值的梯度来确定边缘的位置。Sobel算子有两个方向的滤波器，一个用于检测水平边缘，另一个用于检测垂直边缘。通过计算水平和垂直梯度的组合，可以得到边缘强度。
2. **Canny边缘检测器 / Canny Edge Detector**  
   Canny边缘检测器是最常用的边缘检测方法之一，它包含多个步骤：  
   - **高斯滤波 / Gaussian blur**：用于平滑图像，减少噪声的影响。  
   - **梯度计算 / Gradient Computation**：计算每个像素的梯度方向和幅值。  
   - **非极大值抑制 / Non-Maximum Suppression**：通过抑制非边缘像素来细化边缘。  
   - **双阈值 / Double Threshold**：使用高低两个阈值来确定强边缘、弱边缘和非边缘区域。  
   - **边缘连接 / Edge Linking**：通过连接弱边缘与强边缘来完成最终的边缘检测。

通过边缘检测，计算机能够从图像中提取出更为清晰、精确的信息，进而完成如目标检测、图像分割等更复杂的任务。

## 3. Canny边缘检测器 Детектор границ Кэнни

Canny边缘检测器Canny Edge Detector是一种多步骤的边缘检测算法，其目标是检测图像中的边缘，同时减少噪声和伪边缘的影响。Canny算法具有以下步骤：  
1. **高斯滤波 / Gaussian Filter**：平滑图像以降低噪声。  
2. **梯度计算 / Gradient Calculation**：计算图像中每个像素点的梯度幅值和方向。  
3. **非极大值抑制 / Non-maximum Suppression**：通过抑制梯度方向上的非最大值像素，精确定位边缘。  
4. **双阈值处理 / Double Thresholding**：使用高低阈值筛选出强边缘和弱边缘。  
5. **边缘连接 / Edge Connection**：通过弱边缘连接强边缘形成最终结果。

## 4. 霍夫变换。直线检测算法。圆形检测算法 Преобразование Хафа. Алгоритм обнаружения линий. Алгоритм обнаружения окружностей

霍夫变换Hough Transform是一种用来从图像中检测几何形状（如直线、圆形等）的方法。其核心思想是将几何形状的检测问题转化为**参数空间（Parameter Space）** 的搜索问题。

### 直线检测 / Line Detection
```python
def hough_line_detection(image, rho, theta, threshold):
    """
    霍夫直线检测伪代码函数

    :param image: 输入图像，通常为边缘检测后的二值图像。
    :param rho: 累积器中距离分辨率，单位为像素。
    :param theta: 累积器中角度分辨率，单位为弧度。θ值
    :param threshold: 最小投票数，表示检测到直线所需的支持点数。
    :return: 检测到的直线的参数 (rho, theta)。
    """
    lines = cv2.HoughLines(edges, rho=1, theta=np.pi/180, threshold=100)
    return lines
```

### 圆形检测 / Circle Detection
```python
def hough_circle_detection(image, dp, min_dist, param1, param2, min_radius, max_radius):
    """
    霍夫圆形检测伪代码函数

    :param image: 输入图像，通常为灰度图像。
    :param dp: 累积器分辨率与输入图像分辨率的反比关系。
    :param min_dist: 检测到的圆之间的最小距离，避免多个重叠圆。
    :param param1: Canny边缘检测的高阈值。
    :param param2: 用于圆心检测的累积器阈值。
    :param min_radius: 检测圆的最小半径。
    :param max_radius: 检测圆的最大半径。
    :return: 检测到的圆的参数 (x, y, r)。
    """
    circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT, dp, min_dist, param1=param1, param2=param2, minRadius=min_radius, maxRadius=max_radius)
    return circles
```

## 5. 图像上的特征点检测。Moravec检测器 Обнаружение особых точек на изображении. Детектор Моравеца

**Moravec检测器**是最早的**角点(Угол | Corner)** 检测算法之一，用于在图像中识别具有显著特征的点（如角点）。其基本思想是：一个点在多个方向上的灰度变化显著时，可被认为是一个特征点。

Moravec检测器通过计算像素邻域在各个方向上的强度变化，判断某个像素点是否是角点。如果变化超过一定的阈值，则该点被标记为角点。

## 6. 图像上的特征点检测。Harris检测器。Shi-Tomasi检测器 Обнаружение особых точек на изображении. Детектор Харриса. Детектор Shi-Tomasi

**Harris检测器**是基于图像灰度变化的角点检测算法，其利用**计算图像中每个像素(Pixel)的自相关矩阵**来评估一个点是否是角点。它的特点是能够检测到稳定、显著的角点，且对噪声较为鲁棒。  
**Shi-Tomasi检测器**是对Harris检测器的改进版本，它通过直接比较**矩阵的最小特征值**来判断角点的显著性，而非通过组合特征值的响应函数，从而提高了检测精度。

## 7. 尺度不变特征变换（SIFT）Scale-Invariant Feature Transform (SIFT) | Масштабно-инвариантное преобразование признаков (SIFT)

**SIFT**（Scale-Invariant Feature Transform）是一种用于检测和描述图像局部特征点的算法，具有**尺度不变性Scale Invariance**、**旋转不变性Rotation Invariance**以及**部分仿射变换不变性**。SIFT通过检测图像中的稳定特征点并为其计算描述符，广泛用于图像匹配、拼接、三维重建、物体识别等计算机视觉任务。
SIFT的核心思想是，在不同的尺度下检测图像的**特征点Feature Point**，通过对每个关键点周围的局部区域进行描述，使得即使图像旋转、缩放或改变亮度，仍然能够找到相似的特征点。

## 8. 图像分类任务的定义。线性分类器、支持向量机（SVM）、视觉词袋模型 Постановка задачи классификации изображений. Линейный классификатор. SVM. Мешок визуальных слов  
**图像分类**是计算机视觉中的基础任务之一，其目标是将图像划分到一个或多个预定类别中。为了实现这一目标，通常会通过特征提取方法将图像转化为数值向量，再通过机器学习模型进行分类。常见的图像分类方法包括**支持向量机**（SVM）和**视觉词袋模型**（Bag of Visual Words, BoVW）。
### SVM（支持向量机）
SVM是一种经典的监督学习方法，主要用于二分类和多分类问题。SVM通过寻找一个“最佳超平面”将不同类别的样本进行分离，它具有较强的泛化能力，能够在高维空间中处理复杂的分类任务。对于图像分类，SVM通常结合图像的局部特征（如SIFT、HOG等）来进行分类。
### 视觉词袋模型（BoVW）
视觉词袋模型借鉴了自然语言处理中的词袋模型。它将图像中的特征描述符（如SIFT）进行量化，生成一个固定大小的“视觉词汇”，然后通过这些视觉词汇来表示图像。每个图像被看作是一个“词袋”，而分类则通过这些“视觉单词”的频率分布进行。

## 9. 图像分类神经网络的架构 Архитектура нейронной сети для классификации изображений

**图像分类任务中的神经网络架构**旨在通过一系列特定设计的网络层次，自动从图像中提取特征并进行类别预测。架构的设计直接影响分类性能，包括模型的准确性、训练效率和泛化能力。

---
### 1. **LeNet-5**  
最早期的图像分类神经网络，用于手写数字识别。  
- 两个卷积层（提取低级特征，如边缘和角点）。
- 两个平均池化层（减少特征维度）。
- 全连接层用于分类。

### 2. **AlexNet**  
标志深度学习在图像分类领域的崛起，用于ImageNet大规模分类任务。  
- 引入了 **ReLU 激活函数**，提升了非线性表示能力。
- 使用了 **Dropout** 防止过拟合。
- 包含 5 层卷积层和 3 层全连接层。

### 3. **VGG（VGG-16 和 VGG-19）**  
通过更深的网络实现更好的分类性能。  
- 使用多个 3×3 的卷积核堆叠而成，代替大尺寸卷积核。
- 深度为 16 或 19 层，具有明确的层次设计。
- 参数量较大，但分类精度高。

### 4. **Inception（GoogleNet）**  
通过模块化设计，提高了分类性能并减少了参数量。  
- **Inception 模块**：在不同尺度上并行提取特征，包含 1×1、3×3 和 5×5 卷积核。
- 使用 **1×1 卷积核**减少通道数，提高计算效率。
- 模型更轻量化，性能高。

### 5. **ResNet（Residual Network）**  
解决深层网络中的梯度消失问题，实现非常深的网络（如 ResNet-50 和 ResNet-101）。  
- **残差模块（Residual Block）**：通过跳跃连接（skip connection）直接将输入传递到后续层，避免梯度消失。
- 支持超过 100 层的深度设计，同时保持高效训练。

### 6. **DenseNet（Densely Connected Network）**  
进一步优化特征传递和重用，提高训练效率。  
- **密集连接（Dense Connections）**：每一层都与之前的所有层连接，确保特征最大化共享。
- 使用较少的参数实现较高的分类精度。

## 10. 图像上目标定位问题的定义。评价指标 Постановка задачи локализации объекта на изображении. Метрики.

**物体定位**（Object Localization）是计算机视觉中的一个任务，它的目标是在图像中精确地确定一个或多个物体的位置。通常，定位任务不仅需要识别物体的类别，还要标注其在图像中的位置，通常是通过边界框（bounding box）来表示。
在物体检测任务中，物体定位的精度评估是非常重要的，它直接影响到检测算法的效果。定位精度通常通过不同的**度量标准**来衡量。
### 评估标准
1. **交并比（IoU, Intersection over Union）**  
   **交并比**是用于评估预测边界框与真实边界框重叠度的一个指标。IoU 是通过计算预测框与真实框的交集面积Intersection与它们的并集面积Union之比来得到的。其公式为：
   \[
   IoU = \frac{Area\ of\ Intersection}{Area\ of\ Union}
   \]
   - **值范围**：0 到 1，值越大表示预测框与真实框的重叠程度越高，检测精度越高。
   - **应用**：IoU 用于决定检测结果是否是一个有效的检测，通常会设置一个阈值（如 0.5），如果 IoU 大于该阈值，则认为检测是有效的。
2. **定位精度**  
   定位精度是指预测的边界框与真实边界框之间的位置误差。常见的度量方式有：
   - **中心点误差**：计算预测边界框的中心点与真实边界框中心点之间的距离。
   - **边界框尺寸误差**：比较预测框与真实框的宽度和高度之间的差异。
3. **平均精度（mAP, mean Average Precision）**  
   平均精度是物体检测中常用的评价指标，通常用来评估多个物体类别下的检测性能。mAP 是通过计算每个类别的平均精度（AP），然后对所有类别的 AP 进行平均得到的。AP 的计算方法一般是通过绘制精度-召回曲线并计算其下面积。
   - **公式**：mAP = \(\frac{1}{n} \sum_{i=1}^{n} AP_i\)
     - \(n\)：类别的总数
     - \(AP_i\)：类别 i 的平均精度。
   mAP 越高，说明检测模型在各个类别上的检测效果越好。
4. **召回率与精确率（Recall & Precision）**
   - **精确率（Precision）**：预测为正样本的边界框中，真正为正样本的比例。
     \[
     Precision = \frac{TP}{TP + FP}
     \]
     其中 TP 是真正例，FP 是假正例。
   - **召回率（Recall）**：所有真实正样本中，被正确预测的比例。
     \[
     Recall = \frac{TP}{TP + FN}
     \]
     其中 TP 是真正例，FN 是假负例。
   在定位任务中，精确率和召回率通常是相互制约的，因此需要平衡这两者。

## 11. 用于目标定位的神经网络架构 Архитектура нейронной сети для локализации объекта на изображении

物体定位（Object Localization）任务的目标是检测图像中一个或多个物体的位置，并用**边界框（Bounding Box）** 标注出来，同时确定物体的类别。实现这一任务的神经网络架构需要同时预测物体的类别和位置。

在物体定位任务中，通常采用卷积神经网络（CNN）作为基础架构，并在其基础上增加专门设计的模块，用于预测边界框和类别。

### 常见神经网络架构
#### 1. **YOLO（You Only Look Once）**
YOLO 是一种实时物体检测架构，也适用于物体定位。它通过单次前向传播完成图像的全局定位和分类。
- **工作原理**：
  - 将图像分割为 \(S \times S\) 网格。
  - 每个网格预测一定数量的边界框（Bounding Boxes）和其置信度。
  - 同时预测每个边界框中物体的类别。
- **特点**：
  - 快速且实时，适合嵌入式和实时应用。
  - 对小物体定位可能效果欠佳。


#### 2. **Faster R-CNN**
Faster R-CNN 是一种两阶段检测器，专为高精度的物体定位任务设计。
- **工作原理**：
  1. 使用区域提议网络（RPN）生成候选区域（Proposals）。
  2. 使用共享卷积特征对候选区域进行分类和边界框回归。
- **特点**：
  - 精度高，适合复杂场景。
  - 对小物体定位效果较好，但速度相对较慢。

#### 3. **SSD（Single Shot MultiBox Detector）**
SSD 是一种单阶段检测器，通过多个特征层同时检测不同尺度的物体。
- **工作原理**：
  - 使用多个特征层提取不同尺度的特征。
  - 每个特征层直接预测边界框和类别。
- **特点**：
  - 快速高效，适合实时应用。
  - 对小物体的检测能力强于 YOLO，但弱于 Faster R-CNN。

### 关键模块
1. **边界框回归（Bounding Box Regression）**  
   神经网络通过回归计算出每个边界框的四个参数：\( (x, y, w, h) \)，分别代表边界框的中心坐标和宽、高。
2. **损失函数**  
   - **分类损失**：用于计算类别预测的误差，常用交叉熵损失（Cross-Entropy Loss）。
   - **定位损失**：用于计算边界框预测与真实框之间的差距，常用 \(L_1\) 或 \(L_2\) 损失。
3. **多尺度特征提取**  
   多尺度特征（如 SSD 中的多特征层）可以提高对不同大小物体的定位精度。

### 总结
在物体定位任务中，神经网络架构需要兼顾**定位精度**和**计算效率**。Faster R-CNN 提供高精度，但速度较慢；YOLO 和 SSD 通过单阶段检测实现实时性能。根据具体应用场景，选择合适的架构非常关键。

## 12. 图像目标检测问题的定义。R-CNN Постановка задачи обнаружения объектов на изображении. R-CNN

R-CNN（Regions with Convolutional Neural Networks）是一种经典的物体检测方法，其目标是识别图像中的多个物体，同时预测每个物体的边界框和类别。R-CNN 通过结合**区域提议方法**和**卷积神经网络（CNN）**实现物体的精确检测。

### R-CNN 的核心流程
1. **区域提议（Region Proposals）**  
   使用选择性搜索（Selective Search）算法在图像中生成大约 2000 个候选区域。这些区域覆盖了图像中可能包含物体的所有位置。
2. **特征提取（Feature Extraction）**  
   将每个候选区域缩放为固定大小（如 224×224），并使用预训练的CNN（如 AlexNet 或 VGG）提取区域的特征。
3. **分类（Classification）**  
   使用支持向量机（SVM）对提取的特征进行分类，判断该区域是否属于某个目标类别。
4. **边界框回归（Bounding Box Regression）**  
   对预测的边界框进行精细调整，使其更接近真实物体的边界。

#### 优点
- **高检测精度**：通过 CNN 提取特征，大幅提高了检测精度。
- **模块化设计**：特征提取、分类和回归是独立的模块，便于单独优化。
#### 缺点
- **计算效率低**：每个候选区域都需要单独通过 CNN 进行前向传播，导致速度非常慢。
- **存储开销大**：需要存储大量的区域特征，内存占用较高。

### 应用场景
1. **医学影像分析**  
   在 X 光片或 MRI 图像中检测异常区域（如肿瘤）。
2. **自动驾驶**  
   在车载图像中检测其他车辆、行人和交通标志。
3. **遥感图像处理**  
   在卫星图像中定位建筑物、农田或船只。

### 总结  
R-CNN 是物体检测领域的开创性方法，通过结合区域提议和卷积神经网络实现了高精度的物体检测。然而，由于计算效率低，它更适合对实时性要求较低的场景。后续的改进方法（如 Fast R-CNN 和 Faster R-CNN）克服了这一缺点，大幅提高了检测速度和实用性。

## 13. 图像目标检测方法：Fast R-CNN和Faster R-CNN Обнаружения объектов на изображении. Fast R-CNN и Faster R-CNN

Fast R-CNN 和 Faster R-CNN 是基于 R-CNN 改进的物体检测方法，旨在提高检测效率和精度。它们通过优化区域提议和特征共享机制，解决了 R-CNN 的**计算效率低**和**存储开销大**的问题。

### Fast R-CNN 的核心改进
1. **共享卷积特征**  
   - Fast R-CNN 对整个输入图像只进行一次卷积操作，生成共享的特征图。
   - 每个候选区域（RoI）通过 RoI 池化层（Region of Interest Pooling）从共享特征图中提取区域特征，而无需重复计算。
2. **RoI 池化层（RoI Pooling）**  
   - 将候选区域映射到共享特征图，并通过池化操作将区域特征变为固定大小的输出。
   - 解决了不同大小的候选区域无法直接输入全连接层的问题。
3. **端到端训练**  
   - Fast R-CNN 将分类和边界框回归整合到同一个神经网络中，可以同时优化这两个任务。
4. **速度提升**  
   - 通过共享特征图和减少冗余计算，Fast R-CNN 相较于 R-CNN 提升了 10 倍以上的检测速度。

### Faster R-CNN 的核心改进
1. **引入区域提议网络（RPN）**  
   - Faster R-CNN 使用 RPN 替代传统的选择性搜索方法，直接从特征图中生成区域提议。
   - RPN 是一个小型神经网络，通过滑动窗口的方式预测每个位置的候选区域。
2. **全卷积特征共享**  
   - RPN 和 Fast R-CNN 共享同一套卷积特征图，进一步提升了计算效率。
3. **端到端训练**  
   - Faster R-CNN 通过联合训练 RPN 和检测网络，使整个流程完全端到端，从而提升了检测精度和训练效率。

---
Fast R-CNN 和 Faster R-CNN 是物体检测领域的重要突破。Fast R-CNN 通过共享特征图和 RoI 池化提高了效率，而 Faster R-CNN 进一步引入 RPN，整合了区域提议与检测任务，成为高精度检测的主流方法。虽然 Faster R-CNN 相较于实时检测方法（如 YOLO）速度略慢，但其精度优势使其适合精度要求较高的场景。

## 14. 图像目标检测方法：单发检测器（Single Shot Detector, SSD） Обнаружения объектов на изображении. Single Short Detector

SSD（Single Shot MultiBox Detector）是一种单阶段物体检测方法，它直接从图像中预测目标的类别和边界框，跳过了传统两阶段检测器（如 Faster R-CNN）的区域提议步骤。SSD 的设计兼顾了检测速度和精度，使其适用于实时检测场景。

### SSD 的核心思想
1. **多尺度特征检测**  
   - SSD 在卷积网络的多个层次上进行预测，这些特征层具有不同的**感受野(Receptive Field)**，能够同时检测大物体和小物体。
2. **卷积特征共享**  
   - 通过共享特征图，SSD 避免了重复计算，提高了检测效率。
3. **直接预测边界框和类别**  
   - SSD 在每个特征图位置直接预测边界框的坐标和对应的物体类别，无需额外的分类器或区域提议网络。
4. **默认框（Default Boxes）**  
   - SSD 为每个特征图位置预定义了一组不同尺度和宽高比的默认框（Anchors），这些框与真实框进行匹配，并通过回归调整预测框。

### SSD 的工作流程
1. **输入图像**  
   将输入图像通过基础卷积网络（如 VGG16 或 MobileNet），提取高维特征图。
2. **多尺度特征层**  
   从不同大小的特征层生成边界框预测：
   - 较浅的层负责检测小物体。
   - 较深的层负责检测大物体。
3. **分类和回归**  
   每个特征图位置直接预测：
   - **类别概率**：物体属于各类的概率。
   - **边界框坐标**：预测框相对于默认框的偏移。
4. **非极大值抑制（NMS）**  
   对多余的边界框进行抑制，仅保留具有最高置信度的框。

#### 优点
1. **高效**：通过单阶段检测，避免了区域提议和分类的分离，速度比两阶段方法更快。
2. **实时性能**：SSD 在标准硬件（如 GPU）上可以实现实时检测。
3. **多尺度检测**：利用多特征层进行预测，对大物体和小物体均有较好的检测效果。
#### 缺点
1. **对小物体不够敏感**：虽然多尺度设计改进了小物体检测，但精度仍然不及 Faster R-CNN。
2. **复杂背景中的性能下降**：在背景复杂的图像中，可能存在误检或漏检。

### 应用场景
1. **实时场景分析**  
   在自动驾驶、视频监控和机器人视觉中，SSD 可实现实时检测和响应。
2. **轻量级设备检测**  
   在资源受限的设备（如嵌入式设备、手机）上，SSD 提供了快速、高效的物体检测方案。
3. **智能家居**  
   用于家用摄像头中的实时物体检测，如识别快递包裹或入侵者。
---
SSD 是一种高效的单阶段检测方法，结合了多尺度特征检测和快速推理，能够在保持高检测精度的同时实现实时性能。相比于两阶段方法（如 Faster R-CNN），SSD 在速度上具有显著优势，但在小物体检测和复杂场景中仍有提升空间。它的设计理念为后续检测器（如 YOLOv3、YOLOv4）提供了重要启发。

## 15. 图像分割问题的定义。全卷积网络（FCN） Постановка задачи сегментации изображений. FCN

全卷积网络（Fully Convolutional Network, FCN）是一种用于**图像分割**的神经网络架构。与传统的卷积神经网络（CNN）不同，FCN 将网络的最后几层全连接层替换为卷积层，从而实现对输入图像中每个像素的分类。FCN 是语义分割的基础方法。

### FCN 的核心思想
1. **全卷积结构**  
   - FCN 中没有全连接层，所有层都是卷积层（包括普通卷积和反卷积）。
   - 全卷积结构允许网络接受任意大小的输入图像，而输出的特征图与输入保持对应关系。
2. **像素级分类**  
   - FCN 的目标是为图像中的每个像素分配一个类别标签，这不同于图像分类任务只输出单个类别。
3. **上采样（Upsampling）**  
   - 使用反卷积（Transpose Convolution）操作将特征图的空间分辨率恢复到原始输入图像的大小。
   - 上采样操作使得输出与输入图像的每个像素一一对应。
4. **跳跃连接（Skip Connection）**  
   - FCN 引入了跳跃连接机制，将浅层特征与深层特征结合，使分割结果既包含高层语义信息，又保留了低层的空间细节。

### FCN 的架构
1. **下采样阶段（Downsampling）**  
   - 使用普通卷积和池化层提取图像特征，同时逐步降低特征图的空间分辨率。
2. **上采样阶段（Upsampling）**  
   - 使用反卷积层将低分辨率的特征图逐步上采样，恢复到输入图像的大小。
3. **跳跃连接**  
   - 将下采样阶段的中间特征图与上采样阶段的特征图融合，增强分割的空间精度。

#### 优点
1. **端到端训练**  
   - FCN 支持从原始输入图像到像素级分类结果的端到端训练，简化了分割流程。
2. **像素级预测**  
   - 直接对每个像素进行分类，分割结果更加细致。
3. **灵活输入大小**  
   - 由于全卷积结构，FCN 可以处理任意大小的输入图像。
#### 缺点
1. **细节丢失**  
   - 下采样阶段会导致空间信息丢失，影响分割边界的精确性。
2. **高计算成本**  
   - 大尺寸图像的分割计算开销较高，尤其是在高分辨率输入时。

## 16. U-Net架构 Архитектура U-Net

**U-Net** 是一种用于**医学图像分割**的全卷积神经网络架构，由 Olaf Ronneberger 等人在 2015 年提出。其独特的 U 型结构使其能够在高效捕获上下文信息的同时保留分割的空间精度，成为图像分割领域的经典模型。

### U-Net 的核心思想
1. **对称的编码-解码结构**  
   - **编码部分（Contracting Path）**：通过卷积和池化逐步压缩特征图，提取高层语义信息。
   - **解码部分（Expanding Path）**：通过反卷积（上采样）逐步恢复特征图的空间分辨率。
2. **跳跃连接（Skip Connections）**  
   - 将编码部分中每一层的特征与解码部分的对应层特征进行拼接（Concatenate）。
   - 跳跃连接增强了分割结果的细节表现，使得模型既能捕获全局上下文信息，又能保留精细的边界信息。
3. **像素级预测**  
   - 网络最终输出与输入图像相同大小的特征图，每个像素对应一个类别标签。

### U-Net 的架构
1. **编码部分**  
   - 每层由两次卷积操作（通常使用 \(3 \times 3\) 卷积核）和一次最大池化操作组成。
   - 卷积层提取特征，池化层减小特征图的大小，逐步提取更高层的语义信息。
2. **解码部分**  
   - 每层由一次反卷积操作（上采样）和两次卷积操作组成。
   - 反卷积逐步恢复空间分辨率，卷积层进一步细化特征。
3. **跳跃连接**  
   - 从编码部分引入的跳跃连接将低层特征直接拼接到解码部分的对应层，保留了低层特征的空间细节。

#### 优点
1. **适合小样本数据**  
   - 在医学领域，小样本数据常见，而 U-Net 的设计可以在少量数据上表现出色。
2. **高分辨率分割**  
   - 跳跃连接机制显著提高了分割边界的精度。
3. **灵活性强**  
   - 可以处理任意大小的输入图像，并适配多种分割任务。
#### 缺点
1. **计算资源消耗大**  
   - 由于对高分辨率特征的处理，U-Net 在训练和推理时需要较高的内存和计算能力。
2. **对小物体分割的限制**  
   - 在复杂场景中，可能需要改进以更好地捕捉小物体的特征。

---
U-Net 是一种经典的分割网络，其对称的编码-解码结构和跳跃连接设计使其在多种图像分割任务中表现卓越。尽管 U-Net 最初是为医学图像分割设计的，但它的灵活性和高效性使其被广泛应用于其他分割任务。U-Net 的设计理念还启发了后续许多改进模型（如 ResU-Net、3D U-Net）。

## 17. Mask R-CNN架构 Архитектура Mask R-CNN

**Mask R-CNN** 是一种扩展 Faster R-CNN 的神经网络架构，不仅能够检测图像中的物体并预测其边界框，还能够对每个物体生成精确的像素级分割掩码（Mask）。Mask R-CNN 结合了物体检测和实例分割的能力，是实例分割任务中的经典方法。
### Mask R-CNN 的核心思想
1. **扩展 Faster R-CNN**  
   - 在 Faster R-CNN 的基础上增加了一个分支，用于预测每个物体的分割掩码。
   - 原有的目标检测分支用于预测物体类别和边界框，新分支用于像素级分割。
2. **RoIAlign**  
   - 将 Faster R-CNN 中的 RoI Pooling 替换为 RoIAlign。
   - RoIAlign 消除了量化误差，通过双线性插值精确地对齐特征，显著提升了分割精度。
3. **多任务学习**  
   - Mask R-CNN 通过联合优化三个任务：
     - **分类任务**：预测物体类别。
     - **边界框回归任务**：精确定位物体边界。
     - **分割任务**：为每个物体生成像素级掩码。
### Mask R-CNN 的架构
1. **骨干网络（Backbone Network）**  
   - 使用 ResNet 或 ResNeXt 作为骨干网络提取图像特征。
   - 特征金字塔网络（FPN）进一步增强了对多尺度物体的检测能力。
2. **区域提议网络（RPN）**  
   - RPN 生成一组候选区域（RoIs），用于后续的分类、回归和分割。
3. **RoIAlign**  
   - 对每个候选区域进行特征对齐，生成固定大小的特征图。
4. **分支网络**  
   - **分类分支**：预测物体的类别。
   - **回归分支**：预测边界框的精确位置。
   - **分割分支**：生成每个物体的像素级掩码，分割分支通常由全卷积网络（FCN）构成。
#### 优点
1. **高精度实例分割**  
   - Mask R-CNN 在 COCO 数据集上的实例分割任务中表现出色，精度高。
2. **多功能性**  
   - 兼具目标检测和实例分割能力。
3. **鲁棒性强**  
   - 通过 RoIAlign 解决了特征对齐问题，对边界和掩码分割精度有显著提升。
#### 缺点
1. **计算复杂度高**  
   - 由于分割分支的增加，Mask R-CNN 的计算成本比 Faster R-CNN 更高。
2. **实时性不足**  
   - 不适合实时检测任务，推理速度较慢。
### 应用场景
1. **自动驾驶**  
   - 检测并分割道路上的车辆、行人和交通标志，为场景理解提供精确的信息。
2. **医疗图像分析**  
   - 分割病灶或器官区域，例如从 CT 或 MRI 图像中分割肿瘤。
3. **视频监控**  
   - 实例分割用于识别和跟踪监控视频中的人物或物体。
4. **机器人视觉**  
   - 为机器人提供精确的物体分割，便于物体抓取和操作。
5. **图像编辑**  
   - 分割图像中的特定物体，用于照片修饰或内容提取。
---
Mask R-CNN 是一种将目标检测和实例分割无缝结合的强大方法，其对精确度和功能性的追求使其在许多任务中成为首选。尽管计算成本较高，但其性能优势使其适用于对精度要求较高的应用场景。Mask R-CNN 的架构还启发了许多后续分割和检测模型的设计。

## 18. Lucas-Kanade光流估计方法 Метод оценки оптического потока Лукаса-Канаде

**Lucas-Kanade 方法**是一种经典的光流估计方法，主要用于计算图像中像素的运动向量。该方法假设：
1. 图像中相邻帧之间的运动是小幅的。
2. 图像局部区域内的光流是常量。
光流估计Optical Flow Estimation的目标是通过比较图像序列中的相邻帧，推断出像素Пиксель的运动方向和速度Movement direction and speed。

### 核心思想
Lucas-Kanade 方法基于以下关键假设和计算：
1. **光流约束方程**  
   - 假设图像亮度随时间保持不变：
     \[
     I(x, y, t) = I(x + \Delta x, y + \Delta y, t + \Delta t)
     \]
   - 展开后近似为：
     \[
     \frac{\partial I}{\partial x} u + \frac{\partial I}{\partial y} v + \frac{\partial I}{\partial t} = 0
     \]
     其中：
     - \(u, v\)：光流在 \(x\) 和 \(y\) 方向的分量。
     - \(\frac{\partial I}{\partial x}, \frac{\partial I}{\partial y}\)：图像的空间梯度。
     - \(\frac{\partial I}{\partial t}\)：时间梯度。
2. **局部一致性假设**  
   - 在一个小窗口内，所有像素具有相同的光流。
   - 构造一个线性方程组，通过最小二乘法求解。
3. **最小二乘解**  
   - 将窗口内的光流表示为矩阵形式：
     \[
     A v = b
     \]
     其中：
     - \(A\) 是梯度矩阵，包含 \(\frac{\partial I}{\partial x}\) 和 \(\frac{\partial I}{\partial y}\)。
     - \(v = [u, v]^T\) 是光流向量。
     - \(b = -\frac{\partial I}{\partial t}\)。

   - 解为：
     \[
     v = (A^T A)^{-1} A^T b
     \]
#### 优点
1. **计算高效**：基于局部运算，适合实时应用。
2. **鲁棒性强**：在光流变化平滑的区域表现较好。
3. **易实现**：适合小型系统或低复杂度应用。
#### 缺点
1. **局部限制**：假设光流在局部窗口内是常量，无法处理大幅运动。
2. **敏感性**：对光照变化和噪声较为敏感。
3. **稀疏性**：仅适用于小幅稀疏光流场，不适合复杂的运动场景。

Lucas-Kanade 方法是一种经典且高效的光流估计方法，适用于小幅平滑运动的场景。尽管其对大幅运动和复杂场景存在局限性，但它的简单性和鲁棒性使其成为计算机视觉中许多实时任务的首选算法之一。后续改进方法（如金字塔 Lucas-Kanade）进一步提升了其性能，扩展了其应用范围。

## 19. Horn-Schunck光流估计方法 Метод оценки оптического потока Horn-Schunck

**Horn-Schunck 方法**是一种全局光流估计算法，它通过在整个图像上引入平滑约束，计算出稠密的光流场（即为图像中每个像素点估计运动向量）。与 Lucas-Kanade 方法不同，Horn-Schunck 方法更关注全局一致性，是一种稠密光流估计技术。
### 核心思想
1. **光流约束方程**  
   - 假设图像亮度在运动过程中保持不变：
     \[
     I(x, y, t) = I(x + \Delta x, y + \Delta y, t + \Delta t)
     \]
   - 线性化后得到光流约束方程：
     \[
     \frac{\partial I}{\partial x} u + \frac{\partial I}{\partial y} v + \frac{\partial I}{\partial t} = 0
     \]
     其中：
     - \(u, v\)：光流在 \(x\) 和 \(y\) 方向的分量。
     - \(\frac{\partial I}{\partial x}, \frac{\partial I}{\partial y}\)：图像的空间梯度。
     - \(\frac{\partial I}{\partial t}\)：时间梯度。
2. **平滑约束Smoothness Constraint**  
   - 假设光流场在全局上是平滑的，即相邻像素点的光流变化很小。
   - 平滑约束通过添加正则化项实现：
     \[
     E = \int \int \left( \frac{\partial I}{\partial x} u + \frac{\partial I}{\partial y} v + \frac{\partial I}{\partial t} \right)^2 dxdy + \alpha \int \int \left( \|\nabla u\|^2 + \|\nabla v\|^2 \right) dxdy
     \]
     其中：
     - 第一项是数据项，确保满足光流约束方程。
     - 第二项是平滑项，约束光流场的变化。
     - \(\alpha\)：正则化系数，用于平衡数据项和平滑项。
3. **优化**  
   - 使用变分法求解能量函数 \(E\)，得到光流场 \(u, v\)。
   - 通过迭代计算逐步逼近最优解。
#### 优点
1. **全局一致性**  
   - 通过平滑约束，Horn-Schunck 方法能够生成稠密光流场，适用于全局运动分析。
2. **高分辨率细节**  
   - 在噪声较低的场景中，可以很好地捕捉细微的运动变化。
3. **理论完整性**  
   - 通过最小化全局能量函数，结果具有明确的物理意义。
#### 缺点
1. **对噪声敏感**  
   - 亮度梯度计算对图像噪声非常敏感，容易影响光流估计的准确性。
2. **复杂度高**  
   - Horn-Schunck 方法需要全局迭代计算，计算成本较高，不适合实时任务。
3. **不适合大幅运动**  
   - 假设小运动和亮度不变性，对于大幅运动和动态光照变化效果较差。

---
Horn-Schunck 方法是一种基于全局优化的光流估计算法，通过引入平滑约束，可以生成稠密的光流场。尽管其计算复杂度较高且对噪声敏感，但在对全局一致性要求较高的场景中仍具有重要应用价值。结合现代图像处理方法（如金字塔结构或深度学习），可以进一步提升其性能。

## 20. 计算光流任务的神经网络 Нейронные сети для задачи вычисления оптического потока

**基于神经网络的光流估计**方法是近年来发展起来的技术，利用深度学习的强大表达能力，直接从图像对中预测光流场。与传统方法（如 Lucas-Kanade 和 Horn-Schunck）相比，神经网络方法具有更高的鲁棒性和更好的泛化能力，尤其是在复杂运动和光照变化场景中表现优异。

---
### 1. **FlowNet 系列**
FlowNet 是首个端到端训练的光流估计神经网络，由 Dosovitskiy 等人在 2015 年提出。
#### FlowNet 架构
- **输入**：相邻两帧图像。
- **网络结构**：
  1. **编码部分**：使用卷积层提取空间和时间特征。
  2. **解码部分**：通过反卷积逐步恢复光流分辨率。
- **输出**：与输入大小相同的稠密光流场。
#### 特点
- 端到端训练，无需手工设计特征。
- 能够处理较大的运动范围。
### 2. **PWC-Net**
PWC-Net 是一种改进的光流估计网络，基于特征金字塔、光流引导和成本卷积设计。
#### PWC-Net 核心改进
1. **金字塔特征提取（Pyramid Feature Extraction）**  
   - 在多尺度下提取图像特征，逐步处理不同尺度的运动。
2. **光流引导特征**  
   - 使用前一级的光流预测指导当前级别的特征对齐。
3. **成本体积（Cost Volume）**  
   - 构建候选匹配的代价矩阵，用于估计特定像素的光流。
#### 特点
- 高效的金字塔结构大幅降低计算复杂度。
- 精度比 FlowNet 更高，特别是对小运动和复杂场景。
### 3. **RAFT（Recurrent All-Pairs Field Transforms）**
RAFT 是近年来最先进的光流估计方法之一，采用迭代优化策略，通过全像素对的递归操作实现高精度光流估计。
#### RAFT 核心改进
1. **全像素对匹配**  
   - 直接计算图像中每个像素与其他像素的相关性。
2. **迭代细化**  
   - 通过多次更新优化光流，确保最终结果精确。
3. **高效实现**  
   - 使用循环网络，计算效率高，内存占用低。
#### 特点
- 高精度光流预测，适用于复杂运动场景。
- 能够很好地处理大幅运动和细微变化。
---
#### 优点
1. **鲁棒性强**  
   - 能够适应复杂场景，包括光照变化、大幅运动和动态背景。
2. **端到端训练**  
   - 不需要手工设计特征，通过大规模数据训练直接学习光流表示。
3. **稠密光流估计**  
   - 输出的光流场对每个像素都提供运动信息。
#### 缺点
1. **依赖大规模数据**  
   - 需要大量带标签的数据进行训练，获取光流标注数据成本较高。
2. **计算资源需求高**  
   - 复杂的网络结构对硬件设备要求较高，不适合实时应用。

---
基于神经网络的光流估计方法（如 FlowNet、PWC-Net 和 RAFT）大幅提升了光流估计的精度和鲁棒性。尽管这些方法对计算资源的需求较高，但它们在自动驾驶、视频处理和动态场景分析等任务中表现出色，为传统光流估计方法提供了强大的替代方案。未来的研究方向可能集中在提升实时性能和减少对标注数据的依赖上。

## 21. 图像中的目标跟踪任务（Object Tracking） Задача отслеживания объектов на изображении (Object Tracking)

**对象跟踪**是计算机视觉中的一个重要任务，目标是在视频序列中识别并连续跟踪图像中的特定对象，记录它们在时间轴上的位置和运动轨迹。与物体检测不同，对象跟踪关注的是在多帧视频中维护目标的身份和运动信息。
### 对象跟踪的分类
#### 1. **基于检测的跟踪（Tracking-by-Detection）**
- **定义**：在每一帧中先检测目标，再通过匹配检测结果实现跟踪。
- **优点**：依赖于强大的目标检测器，适合多目标跟踪。
- **缺点**：检测阶段的误差会影响跟踪精度。
#### 2. **在线跟踪（Online Tracking）**
- **定义**：仅基于当前帧和前几帧的信息进行跟踪。
- **优点**：适用于实时应用，计算效率高。
- **缺点**：对遮挡和快速运动的鲁棒性较差。
#### 3. **离线跟踪（Offline Tracking）**
- **定义**：利用整个视频序列的全局信息进行跟踪。
- **优点**：能够处理复杂场景和长时间遮挡。
- **缺点**：需要更多的计算资源，不适用于实时任务。
---
### 1. **传统跟踪算法**
- **Mean-Shift**  
  - 基于目标的颜色直方图特征，通过迭代优化寻找目标位置。
  - 优点：计算简单。
  - 缺点：易受背景颜色相似影响。
- **Kalman Filter（卡尔曼滤波）**  
  - 通过估计目标位置的状态，结合噪声模型进行目标预测。
  - 优点：适合线性运动。
  - 缺点：对复杂非线性运动效果不佳。
- **Particle Filter（粒子滤波）**  
  - 使用粒子表示目标状态，适合处理非线性和非高斯分布的跟踪问题。
  - 优点：鲁棒性强。
  - 缺点：计算复杂度高。
- **光流跟踪（Optical Flow Tracking）**  
  - 使用光流方法估计目标像素的运动。
  - 优点：适合小幅运动。
  - 缺点：对遮挡和快速运动敏感。

#### 2. **深度学习跟踪算法**
- **Siamese 网络（如 SiamFC）**  
  - 通过比较模板和搜索区域之间的相似性，实现目标定位。
  - 优点：端到端训练，速度快。
  - 缺点：对目标外观变化敏感。
- **DeepSORT**  
  - 结合检测器和排序算法，通过外观特征和运动信息实现多目标跟踪。
  - 优点：多目标跟踪效果好。
  - 缺点：依赖检测结果的质量。
- **CFNet**  
  - 将相关滤波器嵌入到深度神经网络中，提高跟踪鲁棒性。
  - 优点：处理遮挡和外观变化效果较好。
  - 缺点：速度相对较慢。
- **TransTrack**  
  - 基于 Transformer 的跟踪算法，直接在检测框架中实现跟踪。
  - 优点：强大的全局信息捕获能力。
  - 缺点：计算复杂度高。
---
对象跟踪是一项在动态场景中维护目标身份和位置的重要技术。传统方法（如 Kalman Filter 和 Mean-Shift）适用于简单场景，而深度学习方法（如 SiamFC 和 DeepSORT）则在复杂场景中表现优异。根据应用场景和实时性需求，选择合适的跟踪方法是成功的关键。

## 22. 人脸识别任务。Haar级联分类器 Задача распознавания лиц. Каскады Хаара

**Haar级联分类器**是一种基于机器学习的人脸检测算法，这种方法通过 Haar-like 特征和级联分类器实现高效的人脸检测。尽管它主要用于检测人脸，但也可以扩展到检测其他物体。
### 核心思想
1. **Haar-like 特征**  
   - Haar-like 特征是一种简单的矩形特征，用于表示图像中亮度差异的模式。例如：
     - 两个矩形的亮度差（边缘特征）。
     - 三个矩形的亮度差（线条特征）。
     - 四个矩形的亮度差（中心对比特征）。
2. **积分图（Integral Image）**  
   - 为了快速计算 Haar-like 特征，Haar级联分类器引入了积分图的概念。
   - 积分图的每个像素值表示该像素左上方所有像素的累计和。
   - 使用积分图可以在常数时间内计算任意矩形区域的像素和。
3. **Adaboost 算法**  
   - Adaboost 算法用于从大量 Haar-like 特征中选择最有区分能力的特征。
   - 通过组合弱分类器（每个特征一个弱分类器），构建一个强分类器。
4. **级联分类器**  
   - 将多个强分类器串联在一起，形成一个级联结构。
   - 在检测过程中，如果某一级分类器判定区域为负样本，则直接放弃，无需进入后续级别。
   - 这种机制显著提高了检测效率。

### 工作流程
1. **训练阶段**  
   - 使用大量正负样本训练 Adaboost 分类器，选择最佳 Haar-like 特征。
   - 构建多层级联分类器，每层过滤部分负样本。
2. **检测阶段**  
   - 在输入图像中滑动窗口，并对每个窗口区域应用级联分类器。
   - 如果一个窗口通过了所有级分类器，则判定该窗口包含人脸。
---
#### 优点
1. **实时性强**  
   - 由于级联结构的高效性，Haar级联分类器可实现实时人脸检测。
2. **简单易实现**  
   - 算法的实现逻辑清晰，训练模型可以直接应用。
3. **资源消耗低**  
   - 不依赖 GPU，也能在嵌入式设备上运行。
#### 缺点
1. **对光照和角度敏感**  
   - 对于光照变化和非正面人脸的检测效果较差。
2. **误检率高**  
   - 在复杂背景中可能产生较多误检。
3. **训练过程耗时**  
   - 需要大量正负样本进行训练，过程较为耗时。

## 23. 人脸识别任务。FaceNet方法 Задача распознавания лиц. FaceNet

**FaceNet** 是谷歌于 2015 年提出的一种基于深度学习的人脸识别系统。与传统方法不同，FaceNet 直接将人脸映射到一个 **欧几里得嵌入空间（Euclidean Embedding Space）** 中，使得嵌入特征之间的欧几里得距离可以直接衡量人脸相似性。
### 核心思想
1. **人脸嵌入（Face Embedding）**  
   - FaceNet 的核心目标是将人脸图像映射到一个固定长度的特征向量（通常是 128 维）。
   - 在嵌入空间中：
     - 同一人的嵌入特征之间的距离尽可能小。
     - 不同人的嵌入特征之间的距离尽可能大。
2. **三元组损失（Triplet Loss）**  
   - FaceNet 使用三元组损失函数来优化嵌入：
     \[
     \mathcal{L} = \sum_{i} \max(0, \|f(x^a_i) - f(x^p_i)\|^2 - \|f(x^a_i) - f(x^n_i)\|^2 + \alpha)
     \]
     其中：
     - \(x^a_i\)：Anchor（锚点）。
     - \(x^p_i\)：Positive（与锚点是同一人）。
     - \(x^n_i\)：Negative（与锚点是不同人）。
     - \(\alpha\)：预设的最小边界值（Margin）。
   - 目标是让正样本距离更接近，负样本距离更远。
3. **深度神经网络架构**  
   - FaceNet 使用 Inception 网络作为其特征提取的基础架构。
   - 输入为预处理过的对齐人脸图像，输出为嵌入向量。

### FaceNet 的流程
1. **人脸检测**  
   - 使用传统方法（如 Haar 级联分类器或 MTCNN）检测图像中的人脸区域。
2. **人脸对齐**  
   - 将检测到的人脸进行几何对齐（如基于眼睛或鼻子的关键点对齐），标准化大小。
3. **特征提取Feature Extraction**  
   - 将对齐的人脸图像输入 FaceNet 模型，生成 128 维的嵌入向量。
4. **相似性计算**  
   - 通过计算嵌入向量之间的欧几里得距离，判断两张人脸是否属于同一人。
---
#### 优点
1. **高精度**  
   - 在多个公开人脸验证数据集（如 LFW）上取得了卓越的性能。
2. **统一性**  
   - 统一了人脸验证（1:1 匹配）、人脸识别（1:N 匹配）和聚类的任务。
3. **计算高效**  
   - 生成的固定长度特征向量可以直接用于分类或聚类，减少了后续处理的复杂性。
#### 缺点
1. **训练成本高**  
   - 需要大规模的标注数据和计算资源。
2. **对数据质量敏感**  
   - 模型性能依赖于训练数据的多样性和质量。
3. **存储需求**  
   - 嵌入特征向量需要额外存储，特别是在大规模数据库中。

## 24. 图像检索任务的定义及其解决方法 Постановка задачи поиска изображений. Подходы к её решению

**图像检索**（Image Retrieval）是指从一个图像数据库中，根据输入的查询图像（或文本描述）找到与之相似或相关的图像。其目标是建立一种高效的机制，快速、准确地匹配和排序相关图像。
### 图像检索的任务分类
1. **基于内容的图像检索（CBIR, Content-Based Image Retrieval）**  
   - 使用图像的视觉内容（如颜色、纹理、形状等）进行检索。
   - 典型输入是图像，输出为数据库中与输入图像内容相似的图像。
2. **基于文本的图像检索**  
   - 使用文本描述作为输入，与数据库中的图像进行匹配。
   - 常用于标注了文本标签的图像数据库。
3. **跨模态图像检索**  
   - 输入与检索目标来自不同模态（如文本与图像的匹配）。
---
### 解决方法
#### 1. **传统方法**
- **特征提取**  
  通过提取图像的低级特征实现检索：
  1. **颜色特征**：如颜色直方图。
  2. **纹理特征**：如 Gabor 滤波器、GLCM（灰度共生矩阵）。
  3. **形状特征**：如边缘方向直方图（HOG）。
- **相似性度量**  
  计算查询图像与数据库中图像特征之间的相似度：
  - 欧几里得距离
  - 余弦相似度
- **索引机制**  
  使用索引结构（如 KD 树、LSH）提高检索效率。
---
#### 2. **深度学习方法**
- **卷积神经网络（CNN）特征提取**  
  - 使用预训练的 CNN（如 ResNet、VGG）提取高层语义特征。
  - 将图像嵌入到固定长度的特征向量中，用于相似性比较。
- **端到端模型**  
  - 通过 Siamese 网络或三元组损失网络直接优化图像的相似性。
  - 输出的嵌入特征在语义上具有良好的区分性。
- **跨模态检索模型**  
  - 结合 Transformer 或对抗性网络（GAN），实现文本与图像的相似性学习。
- **哈希检索**  
  - 深度哈希方法将图像嵌入到二进制码空间，以加速大规模检索。
---
#### 3. **结合索引的检索系统**
- **局部敏感哈希（LSH）**  
  - 对特征进行哈希化存储，提高检索速度。
- **向量数据库**  
  - 使用 Annoy、FAISS 等向量数据库管理高维特征，实现高效近似最近邻搜索。

---
图像检索方法从传统特征提取逐步发展到深度学习嵌入，尤其是基于 CNN 的方法显著提升了检索的准确性和语义理解能力。结合高效的索引技术，可以在大规模图像数据库中实现实时、精准的检索，广泛应用于电子商务、医疗和社交媒体等领域。

## 25. 文本识别任务及其解决方法 Задача распознавания текста. Подходы к её решению

**文本识别**（Text Recognition），也称为光学字符识别（OCR, Optical Character Recognition），是从图像中检测并提取文字信息的任务。目标是将图像中的文本内容转化为可编辑的数字化文本。文本识别的典型应用包括文档数字化、车牌识别、自然场景文字识别等。
### 文本识别的任务流程
1. **文本检测（Text Detection）**  
   - 在图像中定位文本区域（通常为矩形框或多边形）。
   - 例如，检测一张文档或街景图像中的所有文字。
2. **文本识别（Text Recognition）**  
   - 从检测到的文本区域中提取字符或单词。
   - 将视觉信息转换为机器可读的文本字符串。
---
### 1. **传统方法**
- **边缘检测与投影分析**  
  - 使用边缘检测算法（如 Canny）检测文本边缘。
  - 通过投影分析定位文本行和字符区域。
- **特征提取与分类**  
  - 使用形状特征（如 HOG）描述字符形状。
  - 结合 SVM 或 k-NN 分类器对字符进行识别。
- **连接组件分析（CCA）**  
  - 基于二值化后的图像，分析连通区域以定位字符。
---
### 2. **深度学习方法**
- **端到端文本检测与识别**  
  - 使用卷积神经网络（CNN）和循环神经网络（RNN）结合，实现从图像直接到文本的预测。
#### (1) 文本检测模型
- **CTPN（Connectionist Text Proposal Network）**  
  - 检测水平文本区域。
  - 通过回归和分类网络生成精确的文本框。
- **EAST（Efficient and Accurate Scene Text Detector）**  
  - 支持多方向文本检测。
  - 使用全卷积网络快速检测文本。
- **PSENet（Progressive Scale Expansion Network）**  
  - 能够处理弯曲文本，通过逐步扩展检测区域提高精度。
#### (2) 文本识别模型
- **CRNN（Convolutional Recurrent Neural Network）**  
  - 结合卷积层、RNN 和 CTC 损失函数，适用于不定长文本的识别。
- **Transformer-based 模型**  
  - 使用 Transformer 结构，结合注意力机制对文本序列进行建模。
- **Attention-OCR**  
  - 基于 CNN 和 Attention 的方法，能处理复杂场景文本。
---
### 3. **结合的方法**
- **多阶段方法**  
  - 第一阶段使用检测模型（如 EAST）定位文本区域，第二阶段使用识别模型（如 CRNN）进行字符提取。
- **统一框架**  
  - 使用端到端方法（如 Mask TextSpotter）同时实现文本检测和识别。

---
文本识别任务从传统基于规则的方法发展到现代深度学习方法，尤其是端到端模型显著提高了检测和识别的精度与效率。结合先进的文本检测与识别技术，文本识别在文档处理、自然场景分析和实时应用中得到了广泛应用，成为人工智能的重要领域之一。


## 计算机视觉关键术语的三语对照与简要解释，按技术领域分类

---

### **基础概念**
1. **像素 (Пиксель / Pixel)**  
   图像最小单位，包含位置和颜色/灰度信息  
2. **灰度值 (Значение градаций серого / Grayscale Value)**  
   像素亮度值，范围通常为0（黑）~255（白）  

---

### **图像处理**
3. **Sobel算子 (Оператор Собеля / Sobel Operator)**  
   边缘检测卷积核，计算水平和垂直梯度  
4. **霍夫变换 (Преобразование Хафа / Hough Transform)**  
   将图像空间几何形状映射到参数空间（Параметрическое пространство / Parameter Space）检测直线/圆  
   - **最小半径 (Минимальный радиус / min_radius)**: 霍夫圆检测参数  

---

### **特征提取**
5. **角点 (Угловая точка / Corner)**  
   图像中两个边缘相交的点（如Moravec/Harris检测）  
6. **特征点 (Особые точки / Feature Point)**  
   具有尺度不变性 (Масштабная инвариантность / Scale Invariance) 和旋转不变性 (Вращательная инвариантность / Rotation Invariance) 的关键点  

---

### **深度学习架构**
7. **卷积层 (Свёрточный слой / Convolutional Layer)**  
   通过卷积核提取局部特征  
8. **激活函数 (Функция активации / Activation Function)**  
   引入非线性（如ReLU、Sigmoid）  
9. **全连接层 (Полносвязный слой / Fully Connected Layer)**  
   将特征映射到分类空间  
10. **跳跃连接 (Пропускное соединение / Skip Connection)**  
    跨层特征融合（如U-Net、ResNet）  

---

### **目标检测与分割**
11. **区域提议网络 (Сеть предложения регионов / RPN)**  
    Faster R-CNN中生成候选区域的子网络  
12. **ROI池化 (Пулинг регионов интереса / ROI Pooling)**  
    将不同尺寸候选区域统一为固定大小特征图  
13. **RoIAlign**  
    改进ROI池化，通过双线性插值消除量化误差  
14. **交并比 (Перекрытие / IoU)**  
    预测框与真实框的重叠度评估指标  
15. **平均精度均值 (Средняя точность / mAP)**  
    多类别检测的平均精度  

---

### **图像分割与特征融合**
16. **反卷积 (Транспонированная свёртка / Transposed Convolution)**  
    通过可学习参数上采样特征图  
17. **上采样 (Апсемплинг / Upsampling)**  
    增大特征图分辨率（如双线性插值）  
18. **下采样 (Даунсемплинг / Downsampling)**  
    减小特征图分辨率（如最大池化）  
19. **特征金字塔 (Пирамида признаков / FPN)**  
    融合多尺度特征（如 `38×38`, `19×19`）  

---

### **光流与跟踪**
20. **运动方向和速度 (Направление и скорость движения / Movement Direction & Speed)**  
    光流矢量描述像素运动  
21. **FlowNet架构**  
    首个端到端光流估计CNN  
22. **PWC-Net**  
    使用金字塔形变卷积（Pyramid Warping）优化光流  
23. **基于检测的跟踪 (Отслеживание через детекцию / Tracking-by-Detection)**  
    依赖目标检测器（如DeepSORT）  

---

### **人脸与文本识别**
24. **Adaboost训练 (Обучение AdaBoost)**  
    集成弱分类器的增强算法  
25. **级联分类器 (Каскадный классификатор / Cascade Classifier)**  
    多级分类器串联加速检测（Haar级联）  
26. **视觉词袋模型 (Мешок визуальных слов / BoVW)**  
    通过特征聚类构建视觉词典  
27. **文本检测 (Детекция текста / Text Detection)**  
    定位图像中文字区域（如CTPN、EAST）  
28. **文本识别 (Распознавание текста / Text Recognition)**  
    识别文字内容（如CRNN、TrOCR）  

---

### **嵌入与度量**
29. **欧几里得嵌入空间 (Евклидово пространство внедрения / Euclidean Embedding Space)**  
    FaceNet将人脸映射到128维空间  
30. **欧氏距离 (Евклидово расстояние / Euclidean Distance)**  
    衡量嵌入向量相似性  

---
